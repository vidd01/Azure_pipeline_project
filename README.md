# Modern Data Engineering with Medallion Architecture using DBT, Databricks, Spark and Azure Cloud 
In this project, we setup and end to end data engineering using Apache Spark, Azure Databricks, Data Build Tool (DBT) using Azure as our cloud provider. This project illustrate the process of data ingestion to the lakehouse, data integration with ADF and data transformation with Databricks, and DBT.


## System Architecture
![Medallion_architecture_data_lake_house](https://github.com/vidd01/Azure_pipeline_project/assets/122332733/42398cae-60c4-4576-b031-1c980f5b331f)


## Steps involved are:
- Creating resource groups on Azure
- Setting up the medallion architecture storage account
- Setting up Azure Data Factory
- Azure Key Vault setup for secrets
- Azure database with automatic data population
- Azure Data Factory pipeline orchestration
- Setting up Databricks
- Azure Databricks Secret Scope and Key Vault
- Verifying Databricks - Key Vault - Secret Scope Integration
- Azure Data Factory - Databricks Integration
- DBT Setup
- DBT Configuration with Azure Databricks
- DBT Snapshots with Azure Databricks and ADLS Gen2
- DBT Data Marts with Azure Databricks and ADLS Gen2
- DBT Documentation 

